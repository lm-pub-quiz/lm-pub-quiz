{
    "P6": {
        "templates": [
            "The head of government of [X] is [Y].",
            "[Y] served as the head of government for [X].",
            "[X] was already governed by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:07:33",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Khalifa bin Zayed Al Nahyan",
            "Kyriakos Mitsotakis",
            "Josip Broz Tito",
            "Miche\u00e1l Martin",
            "Ehud Barak",
            "Nayib Bukele",
            "Leonid Kravchuk",
            "Markus S\u00f6der",
            "Nicola Sturgeon",
            "Saara Kuugongelwa",
            "Jair Bolsonaro",
            "Ali Asadov",
            "George Weah",
            "Hassanal Bolkiah",
            "Ian Paisley",
            "Sheikh Hasina",
            "Mario Abdo Ben\u00edtez",
            "Guadalupe Victoria",
            "Burebista",
            "Idriss D\u00e9by",
            "Ariel Sharon",
            "Pasquale Paoli",
            "Abiy Ahmed Ali",
            "Lee Hsien Loong",
            "Macky Sall",
            "Adama Barrow",
            "Salva Kiir Mayardit",
            "Hun Sen",
            "Pedro S\u00e1nchez",
            "Joko Widodo",
            "Taur Matan Ruak",
            "Sergey Sobyanin",
            "Guillermo Lasso",
            "Askar Mamin",
            "Juan Orlando Hern\u00e1ndez",
            "Enver Hoxha",
            "Hilda C. Heine",
            "Hastings Banda",
            "Alain Jupp\u00e9",
            "Vladimir Lenin",
            "Zdravko Krivokapi\u0107",
            "Isaias Afwerki",
            "Andr\u00e9s Manuel L\u00f3pez Obrador",
            "Brian Mulroney",
            "Helen Clark",
            "Matamela Cyril Ramaphosa",
            "Emil Boc",
            "Joan Enric Vives Sic\u00edlia",
            "Narendra Modi",
            "Mateusz Morawiecki",
            "Kakha Kaladze",
            "Jo\u00e3o Louren\u00e7o",
            "Mark Rutte",
            "Nana Akufo-Addo",
            "David Ben-Gurion",
            "Jawaharlal Nehru",
            "Samia Suluhu",
            "Khadga Prasad Sharma Oli",
            "Gabriele D'Annunzio",
            "Nikol Pashinyan"
        ],
        "answer_space_ids": [
            "Q1059948",
            "Q552751",
            "Q9161",
            "Q920403",
            "Q125731",
            "Q17712353",
            "Q189732",
            "Q50664",
            "Q467112",
            "Q7395683",
            "Q10304982",
            "Q12850075",
            "Q173139",
            "Q57327",
            "Q296597",
            "Q52183",
            "Q48136013",
            "Q311425",
            "Q309869",
            "Q57350",
            "Q60206",
            "Q152346",
            "Q50365049",
            "Q57643",
            "Q57438",
            "Q27917049",
            "Q57315",
            "Q57788",
            "Q6070218",
            "Q3318231",
            "Q57519",
            "Q319497",
            "Q4414537",
            "Q527063",
            "Q5951723",
            "Q53783",
            "Q20090884",
            "Q184945",
            "Q215569",
            "Q1394",
            "Q97999161",
            "Q57348",
            "Q318508",
            "Q128563",
            "Q180383",
            "Q1148669",
            "Q267857",
            "Q57473",
            "Q1058",
            "Q11771436",
            "Q192031",
            "Q28650390",
            "Q57792",
            "Q718601",
            "Q37610",
            "Q1047",
            "Q16193885",
            "Q3195923",
            "Q193236",
            "Q7035479"
        ]
    },
    "P19": {
        "templates": [
            "[X] was born in [Y].",
            "[X]'s place of birth is [Y].",
            "The birthplace of [X] is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 592,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:08:39",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Afghanistan",
            "Belgium",
            "Canada",
            "Denmark",
            "Egypt",
            "Ghana",
            "Iceland",
            "Iran",
            "Israel",
            "Lebanon",
            "Malaysia",
            "Monaco",
            "Nepal",
            "New Zealand",
            "Nigeria",
            "Norway",
            "Pakistan",
            "the Philippines",
            "Poland",
            "Singapore",
            "South Korea",
            "Sweden",
            "Switzerland",
            "Thailand",
            "the United States of America"
        ],
        "answer_space_ids": [
            "Q889",
            "Q31",
            "Q16",
            "Q35",
            "Q79",
            "Q117",
            "Q189",
            "Q794",
            "Q801",
            "Q822",
            "Q833",
            "Q235",
            "Q837",
            "Q664",
            "Q1033",
            "Q20",
            "Q843",
            "Q928",
            "Q36",
            "Q334",
            "Q884",
            "Q34",
            "Q39",
            "Q869",
            "Q30"
        ]
    },
    "P20": {
        "templates": [
            "[X] died in [Y].",
            "[X] passed away in [Y].",
            "[X]'s place of death was [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 594,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:09:40",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Afghanistan",
            "Belgium",
            "Canada",
            "Denmark",
            "Egypt",
            "Ethiopia",
            "Germany",
            "Indonesia",
            "Iraq",
            "Israel",
            "Italy",
            "Monaco",
            "Mongolia",
            "Myanmar",
            "Pakistan",
            "the Philippines",
            "Singapore",
            "South Africa",
            "Sri Lanka",
            "Sweden",
            "Syria",
            "Turkey",
            "the United Kingdom",
            "the United States of America",
            "Vatican City"
        ],
        "answer_space_ids": [
            "Q889",
            "Q31",
            "Q16",
            "Q35",
            "Q79",
            "Q115",
            "Q183",
            "Q252",
            "Q796",
            "Q801",
            "Q38",
            "Q235",
            "Q711",
            "Q836",
            "Q843",
            "Q928",
            "Q334",
            "Q258",
            "Q854",
            "Q34",
            "Q858",
            "Q43",
            "Q145",
            "Q30",
            "Q237"
        ]
    },
    "P26": {
        "templates": [
            "[X] is married to [Y].",
            "[X] has [Y] as a spouse.",
            "[X]'s spouse is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:10:37",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Octave Mirbeau",
            "Carl Sagan",
            "Jennifer Lopez",
            "Jean-Jacques Rousseau",
            "Jackie Chan",
            "Niels Bohr",
            "Robert Burns",
            "Sylvester Stallone",
            "Sigmund Freud",
            "Sarah Bernhardt",
            "Lu Xun",
            "Richard Wagner",
            "Avril Lavigne",
            "Gautama Buddha",
            "Lucretius",
            "Pablo Neruda",
            "Suleiman the Magnificent",
            "Peter Paul Rubens",
            "Ruhollah Khomeini",
            "Bertolt Brecht",
            "James Joyce",
            "Edward Snowden",
            "Elizabeth II",
            "Michael Jackson",
            "Deng Xiaoping",
            "Bing Crosby",
            "Naruhito",
            "Francisco Franco",
            "Francisco de Goya",
            "Jonathan Swift",
            "Friedrich Schiller",
            "Woody Allen",
            "Britney Spears",
            "Al\u012b ibn Ab\u012b \u1e6c\u0101lib",
            "Albert Schweitzer",
            "\u00c9dith Piaf",
            "Natalie Portman",
            "Judy Garland",
            "Joseph Stalin",
            "Queen Victoria",
            "Paulo Coelho",
            "Augusto Pinochet",
            "Meryl Streep",
            "Albert Camus",
            "Maurice Maeterlinck",
            "Otto von Bismarck",
            "Jimmy Wales",
            "Ernest Hemingway",
            "Robert De Niro",
            "Leon Trotsky",
            "Marcus Aurelius",
            "Jorge Luis Borges",
            "Elisha Cuthbert",
            "Salvador Allende",
            "Steven Seagal",
            "Julia Roberts",
            "Sun Yat-sen",
            "Malcolm X",
            "Mikheil Saakashvili",
            "Ashoka"
        ],
        "answer_space_ids": [
            "Q23441",
            "Q410",
            "Q40715",
            "Q6527",
            "Q36970",
            "Q7085",
            "Q81960",
            "Q40026",
            "Q9215",
            "Q4605",
            "Q23114",
            "Q1511",
            "Q30449",
            "Q9441",
            "Q47154",
            "Q34189",
            "Q8474",
            "Q5599",
            "Q38823",
            "Q38757",
            "Q6882",
            "Q13424289",
            "Q9682",
            "Q2831",
            "Q16977",
            "Q72984",
            "Q217096",
            "Q29179",
            "Q5432",
            "Q41166",
            "Q22670",
            "Q25089",
            "Q11975",
            "Q39619",
            "Q49325",
            "Q1631",
            "Q37876",
            "Q11637",
            "Q855",
            "Q9439",
            "Q12881",
            "Q368",
            "Q873",
            "Q34670",
            "Q49747",
            "Q8442",
            "Q181",
            "Q23434",
            "Q36949",
            "Q33391",
            "Q1430",
            "Q909",
            "Q188500",
            "Q440",
            "Q82110",
            "Q40523",
            "Q8573",
            "Q43303",
            "Q43330",
            "Q8589"
        ]
    },
    "P27": {
        "templates": [
            "[X] holds citizenship in [Y].",
            "[X] is a citizen of [Y].",
            "[Y] recognizes [X] as its citizen."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:11:44",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Argentina",
            "Belgium",
            "Canada",
            "Chile",
            "Colombia",
            "Croatia",
            "Ghana",
            "Greece",
            "Iraq",
            "Israel",
            "Malaysia",
            "Mexico",
            "Nigeria",
            "Pakistan",
            "Peru",
            "the Philippines",
            "Singapore",
            "South Africa",
            "South Korea",
            "Switzerland",
            "Syria",
            "Turkey",
            "Ukraine",
            "the United States of America",
            "Uruguay"
        ],
        "answer_space_ids": [
            "Q414",
            "Q31",
            "Q16",
            "Q298",
            "Q739",
            "Q224",
            "Q117",
            "Q41",
            "Q796",
            "Q801",
            "Q833",
            "Q96",
            "Q1033",
            "Q843",
            "Q419",
            "Q928",
            "Q334",
            "Q258",
            "Q884",
            "Q39",
            "Q858",
            "Q43",
            "Q212",
            "Q30",
            "Q77"
        ]
    },
    "P30": {
        "templates": [
            "[X] is located in [Y].",
            "[X] is a part of [Y].",
            "[X] is situated in [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:11:55",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Africa",
            "Antarctica",
            "Asia",
            "Europe",
            "North America",
            "South America"
        ],
        "answer_space_ids": [
            "Q15",
            "Q51",
            "Q48",
            "Q46",
            "Q49",
            "Q18"
        ]
    },
    "P36": {
        "templates": [
            "The capital of [X] is [Y].",
            "[X] has its governmental seat in [Y].",
            "[Y] serves as the capital of [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:12:49",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Kolkata",
            "Rabat",
            "Sumatra",
            "Rostov-on-Don",
            "Zhengzhou",
            "Juba",
            "Mexico City",
            "Porto-Novo",
            "Tehran",
            "Islamabad",
            "Pristina",
            "Palermo",
            "Johannesburg",
            "Nairobi",
            "Abidjan",
            "Doha",
            "Tashkent",
            "Kaliningrad",
            "Bengaluru",
            "Bamako",
            "Minneapolis",
            "Washington, D.C.",
            "Bristol",
            "Xi'an",
            "Edirne",
            "Genoa",
            "Rio de Janeiro",
            "Lviv",
            "Belgrade",
            "Hanoi",
            "Thessaloniki",
            "Brisbane",
            "Bissau",
            "Harare",
            "Bilbao",
            "Yaound\u00e9",
            "Nantes",
            "Auckland",
            "Beijing",
            "Managua",
            "Conakry",
            "Kaunas",
            "Antwerp",
            "Riga",
            "Vilnius",
            "Krak\u00f3w",
            "Vaduz",
            "Veliko Tarnovo",
            "Mainz",
            "Pittsburgh",
            "Taipei",
            "Valletta",
            "Yerevan",
            "Dushanbe",
            "Juneau",
            "Thimphu",
            "Cardiff",
            "Liverpool",
            "Luxembourg",
            "City of Brussels"
        ],
        "answer_space_ids": [
            "Q1348",
            "Q3551",
            "Q3492",
            "Q908",
            "Q30340",
            "Q1947",
            "Q1489",
            "Q3799",
            "Q3616",
            "Q1362",
            "Q25270",
            "Q2656",
            "Q34647",
            "Q3870",
            "Q1515",
            "Q3861",
            "Q269",
            "Q1829",
            "Q1355",
            "Q3703",
            "Q36091",
            "Q61",
            "Q23154",
            "Q5826",
            "Q43387",
            "Q1449",
            "Q8678",
            "Q36036",
            "Q3711",
            "Q1858",
            "Q17151",
            "Q34932",
            "Q3739",
            "Q3921",
            "Q8692",
            "Q3808",
            "Q12191",
            "Q37100",
            "Q956",
            "Q3274",
            "Q3733",
            "Q4115712",
            "Q12892",
            "Q1773",
            "Q216",
            "Q31487",
            "Q1844",
            "Q173474",
            "Q1720",
            "Q1342",
            "Q1867",
            "Q23800",
            "Q1953",
            "Q9365",
            "Q29445",
            "Q9270",
            "Q10690",
            "Q24826",
            "Q1842",
            "Q239"
        ]
    },
    "P37": {
        "templates": [
            "The official language of [X] is [Y].",
            "[Y] is designated as the official language of [X].",
            "[X] uses [Y] as its official language."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:13:45",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Tajik",
            "Javanese",
            "Malaysian",
            "Afrikaans",
            "Urdu",
            "Norwegian",
            "Old French",
            "Xhosa",
            "Old East Slavic",
            "Lisan al-Gharbi",
            "Khariboli",
            "Picard",
            "Fula",
            "Cumbric",
            "Bengali",
            "Proto-Slavic",
            "Tarifit",
            "Latvian",
            "Polish",
            "Italian",
            "Piedmontese",
            "Soninke",
            "Esperanto",
            "Kazakh",
            "Castellano",
            "Gujarati",
            "Icelandic",
            "Berber",
            "Burmese",
            "Kokborok",
            "Kumyk",
            "Prakrit",
            "Mongolic",
            "Dagbani",
            "Kannada",
            "Slovene",
            "Vulgar Latin",
            "Azerbaijani",
            "Santiago Creole",
            "Swedish",
            "Hurrian",
            "West Saxon",
            "Tooro",
            "Serbian",
            "Lao",
            "Punic",
            "Pipil",
            "Wanka Quechua",
            "Mandarin Chinese",
            "Marathi",
            "Rohirric",
            "Middle Chinese",
            "Malayalam",
            "Saharan",
            "Biblical Hebrew",
            "Karluk",
            "Primitive Irish",
            "Ukrainian",
            "Hindi",
            "Bosnian"
        ],
        "answer_space_ids": [
            "Q9260",
            "Q33549",
            "Q15065",
            "Q14196",
            "Q1617",
            "Q9043",
            "Q35222",
            "Q13218",
            "Q35228",
            "Q19895801",
            "Q3361977",
            "Q34024",
            "Q33454",
            "Q35965",
            "Q9610",
            "Q747537",
            "Q34174",
            "Q9078",
            "Q809",
            "Q652",
            "Q15085",
            "Q36660",
            "Q143",
            "Q9252",
            "Q15730344",
            "Q5137",
            "Q294",
            "Q25448",
            "Q9228",
            "Q35947",
            "Q36209",
            "Q192170",
            "Q33750",
            "Q32238",
            "Q33673",
            "Q9063",
            "Q37560",
            "Q9292",
            "Q35117",
            "Q9027",
            "Q35740",
            "Q2658603",
            "Q7824218",
            "Q9299",
            "Q9211",
            "Q535958",
            "Q1186896",
            "Q36960",
            "Q9192",
            "Q1571",
            "Q1247809",
            "Q2016252",
            "Q36236",
            "Q1757661",
            "Q1982248",
            "Q703173",
            "Q3320030",
            "Q8798",
            "Q1568",
            "Q9303"
        ]
    },
    "P50": {
        "templates": [
            "[X] was authored by [Y].",
            "[X] is a written work by [Y].",
            "The author of [X] is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 594,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:16:00",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Agatha Christie",
            "Anton Chekhov",
            "Aristotle",
            "C. S. Lewis",
            "Charles Dickens",
            "Edgar Allan Poe",
            "Ernest Hemingway",
            "Franz Kafka",
            "George Bernard Shaw",
            "H. G. Wells",
            "Hans Christian Andersen",
            "Honor\u00e9 de Balzac",
            "Isaac Asimov",
            "J.\u00a0R.\u00a0R. Tolkien",
            "Johann Wolfgang von Goethe",
            "Jorge Luis Borges",
            "Lord Byron",
            "Plato",
            "Robert Louis Stevenson",
            "Rudyard Kipling",
            "Stephen King",
            "Voltaire",
            "William Blake",
            "William Faulkner",
            "William Shakespeare"
        ],
        "answer_space_ids": [
            "Q35064",
            "Q5685",
            "Q868",
            "Q9204",
            "Q5686",
            "Q16867",
            "Q23434",
            "Q905",
            "Q19185",
            "Q42511",
            "Q5673",
            "Q9711",
            "Q34981",
            "Q892",
            "Q5879",
            "Q909",
            "Q5679",
            "Q859",
            "Q1512",
            "Q34743",
            "Q39829",
            "Q9068",
            "Q41513",
            "Q38392",
            "Q692"
        ]
    },
    "P53": {
        "templates": [
            "[X] is a member of the [Y].",
            "[X] belongs to the [Y].",
            "[X] is part of the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:16:45",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Abbasids",
            "Borjigin",
            "Carolingian dynasty",
            "Chakri Dynasty",
            "Chingissid",
            "Dinastia Solomonid\u0103",
            "Eighteenth Dynasty of Egypt",
            "House of Habsburg",
            "House of Hohenzollern",
            "House of Plantagenet",
            "House of Stuart",
            "House of Trast\u00e1mara",
            "House of Valois",
            "House of Wessex",
            "House of Wettin",
            "House of Windsor",
            "House of Wittelsbach",
            "House of Zhu",
            "Imperial House of Japan",
            "Merovingian dynasty",
            "Ottoman dynasty",
            "Piast dynasty",
            "Ptolemaic dynasty",
            "Rurik dynasty",
            "Timurid dynasty"
        ],
        "answer_space_ids": [
            "Q4437641",
            "Q1059073",
            "Q133602",
            "Q691928",
            "Q3100718",
            "Q256187",
            "Q146055",
            "Q65968",
            "Q83969",
            "Q106151",
            "Q179840",
            "Q269876",
            "Q182135",
            "Q511482",
            "Q152909",
            "Q81589",
            "Q131621",
            "Q5185064",
            "Q909452",
            "Q59488",
            "Q193383",
            "Q201615",
            "Q131976",
            "Q210398",
            "Q20737645"
        ]
    },
    "P57": {
        "templates": [
            "[X] was directed by [Y].",
            "[Y] was the director of [X].",
            "The director of [X] was [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:17:51",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Charlie Chaplin",
            "Chuck Jones",
            "Clint Eastwood",
            "Edward Dmytryk",
            "Henry Hathaway",
            "Henry King",
            "Ingmar Bergman",
            "Ishir\u014d Honda",
            "Jean-Luc Godard",
            "John Ford",
            "Ken Loach",
            "Martin Scorsese",
            "Mervyn LeRoy",
            "Michael Curtiz",
            "Norman Taurog",
            "Raoul Walsh",
            "Roger Corman",
            "Sidney Lumet",
            "Spike Lee",
            "Steven Spielberg",
            "Trey Parker",
            "Werner Herzog",
            "William A. Wellman",
            "Wim Wenders",
            "Woody Allen"
        ],
        "answer_space_ids": [
            "Q882",
            "Q312657",
            "Q43203",
            "Q72229",
            "Q457250",
            "Q269505",
            "Q7546",
            "Q150840",
            "Q53001",
            "Q51114",
            "Q55238",
            "Q41148",
            "Q103788",
            "Q51491",
            "Q95111",
            "Q72756",
            "Q318292",
            "Q51559",
            "Q51566",
            "Q8877",
            "Q44414",
            "Q44131",
            "Q290962",
            "Q55411",
            "Q25089"
        ]
    },
    "P58": {
        "templates": [
            "[X] was written by [Y].",
            "[Y] was the screenwriter for [X].",
            "The script for [X] was penned by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:18:35",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Charlie Chaplin",
            "Akira Kurosawa",
            "Woody Allen",
            "Ingmar Bergman",
            "Satyajit Ray",
            "Hayao Miyazaki",
            "Jean-Luc Godard",
            "Pedro Almod\u00f3var",
            "Luc Besson",
            "Larry David",
            "Werner Herzog",
            "Abbas Kiarostami",
            "Spike Lee",
            "Kim Ki-duk",
            "Agn\u00e8s Varda",
            "Richard Matheson",
            "Aki Kaurism\u00e4ki",
            "Blake Edwards",
            "Aaron Sorkin",
            "\u00c9ric Rohmer",
            "Trey Parker",
            "Kamal Haasan",
            "Ed Wood",
            "Peter Greenaway",
            "Neil Simon"
        ],
        "answer_space_ids": [
            "Q882",
            "Q8006",
            "Q25089",
            "Q7546",
            "Q8873",
            "Q55400",
            "Q53001",
            "Q55171",
            "Q484779",
            "Q23728",
            "Q44131",
            "Q55210",
            "Q51566",
            "Q212990",
            "Q229990",
            "Q325130",
            "Q276186",
            "Q56093",
            "Q299194",
            "Q50764",
            "Q44414",
            "Q381477",
            "Q221843",
            "Q55282",
            "Q315808"
        ]
    },
    "P69": {
        "templates": [
            "[X] was educated at the [Y].",
            "[X] received education from [Y].",
            "[X] studied at [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:22:54",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Brown University",
            "Duke University",
            "Harvard University",
            "Imperial College London",
            "Leiden University",
            "Ludwig Maximilian University of Munich",
            "Peking University",
            "Princeton University",
            "Sapienza University of Rome",
            "Stanford University",
            "United States Military Academy",
            "University of Birmingham",
            "University of Calcutta",
            "University of Edinburgh",
            "University of Geneva",
            "University of North Carolina at Chapel Hill",
            "University of Oslo",
            "University of Oxford",
            "University of Southern California",
            "University of Sydney",
            "University of Toronto",
            "University of Vienna",
            "University of Washington",
            "Yale University",
            "York University"
        ],
        "answer_space_ids": [
            "Q49114",
            "Q168751",
            "Q13371",
            "Q189022",
            "Q156598",
            "Q55044",
            "Q16952",
            "Q21578",
            "Q209344",
            "Q41506",
            "Q9219",
            "Q223429",
            "Q1145306",
            "Q160302",
            "Q503473",
            "Q192334",
            "Q486156",
            "Q34433",
            "Q4614",
            "Q487556",
            "Q180865",
            "Q165980",
            "Q219563",
            "Q49112",
            "Q849751"
        ]
    },
    "P87": {
        "templates": [
            "The librettist for the opera [X] was [Y].",
            "[Y] wrote the libretto for [X].",
            "The words for [X] were penned by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:26:01",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Robert Zemeckis",
            "Andrei Voznesensky",
            "Jean-Pierre Claris de Florian",
            "Vladimir Sorokin",
            "Elfriede Jelinek",
            "Alban Berg",
            "Arnold Schoenberg",
            "Sergei Prokofiev",
            "Igor Stravinsky",
            "Eug\u00e8ne Scribe",
            "Neil Simon",
            "Alfred Tennyson",
            "Frederick II of Prussia",
            "Jean Richepin",
            "Eric Idle",
            "Jennifer Saunders",
            "Giuseppe Parini",
            "Leo\u0161 Jan\u00e1\u010dek",
            "Hugo von Hofmannsthal",
            "John Gay",
            "Aleksey Nikolaevich Tolstoy",
            "Alexander Sumarokov",
            "Lin-Manuel Miranda",
            "Stephen Sondheim",
            "Stephen King",
            "Krzysztof Penderecki",
            "Nick Cave",
            "Alois H\u00e1ba",
            "Edward Albee",
            "Doris Lessing",
            "Rabindranath Tagore",
            "Richard Rodgers",
            "Andr\u00e9 Gide",
            "Tina Fey",
            "Gy\u00f6rgy Kurt\u00e1g",
            "J. M. Barrie",
            "Ferruccio Busoni",
            "Michel Fokine",
            "Ossie Davis",
            "Peter Maxwell Davies",
            "John Dryden",
            "Frank Martin",
            "B\u00e9la Bal\u00e1zs",
            "Alphonse Daudet",
            "Magn\u00fas Scheving",
            "Charles Ferdinand Ramuz",
            "Vladimir Nemirovich-Danchenko",
            "Andrew Lloyd Webber",
            "Pierre Beaumarchais",
            "Langston Hughes",
            "Ronald Harwood",
            "John Newton",
            "David Stern",
            "Richard Strauss",
            "Vincent d'Indy",
            "Annie Proulx",
            "Akaki Tsereteli",
            "Thomas Moore",
            "Bj\u00f6rn Ulvaeus",
            "Lillian Hellman"
        ],
        "answer_space_ids": [
            "Q187364",
            "Q236619",
            "Q551740",
            "Q319839",
            "Q47243",
            "Q78475",
            "Q154770",
            "Q49481",
            "Q7314",
            "Q319261",
            "Q315808",
            "Q173869",
            "Q33550",
            "Q551744",
            "Q210741",
            "Q235415",
            "Q529146",
            "Q184933",
            "Q51513",
            "Q321660",
            "Q192279",
            "Q429915",
            "Q1646482",
            "Q153579",
            "Q39829",
            "Q153469",
            "Q192668",
            "Q366711",
            "Q219420",
            "Q40874",
            "Q7241",
            "Q269094",
            "Q47484",
            "Q14540",
            "Q48184",
            "Q81796",
            "Q219551",
            "Q314312",
            "Q515632",
            "Q139223",
            "Q213355",
            "Q123910",
            "Q469963",
            "Q228546",
            "Q529925",
            "Q123635",
            "Q203860",
            "Q180975",
            "Q70326",
            "Q188093",
            "Q706668",
            "Q357301",
            "Q347958",
            "Q13894",
            "Q313584",
            "Q229840",
            "Q379612",
            "Q315346",
            "Q179682",
            "Q233701"
        ]
    },
    "P98": {
        "templates": [
            "[X] was checked and corrected by [Y].",
            "[Y] edited [X].",
            "[X] was edited by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:27:28",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "John Dalberg-Acton, 1st Baron Acton",
            "William Smith",
            "Jimmy Lai",
            "Esther Duflo",
            "Friedrich Schiller",
            "Sylvia Pankhurst",
            "Samuel Johnson",
            "Francisco Jim\u00e9nez de Cisneros",
            "Michael Shermer",
            "Daron Acemo\u011flu",
            "William Blake",
            "Hasbro",
            "Edgar Allan Poe",
            "Alexander Gauland",
            "Michael Moorcock",
            "Johann Wolfgang von Goethe",
            "John W. Campbell",
            "Hugo Gernsback",
            "Hugh Hefner",
            "Orson Scott Card",
            "Frederick Douglass",
            "Aubrey de Grey",
            "Rudolf Rocker",
            "Fyodor Dostoyevsky",
            "Tony Hoare",
            "Karl Kautsky",
            "Menachem Mendel Schneerson",
            "Guillaume Henri Dufour",
            "Stephen King",
            "George Sand",
            "Arnold Schwarzenegger",
            "R. L. Stine",
            "Jean Bourgain",
            "Confucius",
            "Gustav Fechner",
            "Booker T. Washington",
            "Porphyry",
            "Georges Wolinski",
            "H. L. Mencken",
            "Harry Turtledove",
            "Petr Ginz",
            "Lady Randolph Churchill",
            "Philip Larkin",
            "Gjergj Fishta",
            "Andr\u00e9 Breton",
            "Johann Most",
            "William Butler Yeats",
            "Erasmus",
            "Elias L\u00f6nnrot",
            "Pete Seeger",
            "David MacMillan",
            "Vladimir Korolenko",
            "George Co\u0219buc",
            "Paul Heyse",
            "Julius Streicher",
            "Gerard 't Hooft",
            "David Byrne",
            "Kevin J. Anderson",
            "Brian Greene",
            "Michael Praetorius"
        ],
        "answer_space_ids": [
            "Q311778",
            "Q559411",
            "Q1447095",
            "Q434509",
            "Q22670",
            "Q298213",
            "Q183266",
            "Q342392",
            "Q126225",
            "Q718581",
            "Q41513",
            "Q501476",
            "Q16867",
            "Q1670311",
            "Q316138",
            "Q5879",
            "Q435056",
            "Q312242",
            "Q194280",
            "Q217110",
            "Q215562",
            "Q175969",
            "Q213562",
            "Q991",
            "Q92602",
            "Q76586",
            "Q381397",
            "Q123238",
            "Q39829",
            "Q3816",
            "Q2685",
            "Q333123",
            "Q260802",
            "Q4604",
            "Q76881",
            "Q319871",
            "Q203445",
            "Q1375265",
            "Q439204",
            "Q455780",
            "Q445513",
            "Q243011",
            "Q313758",
            "Q115455",
            "Q161955",
            "Q213632",
            "Q40213",
            "Q43499",
            "Q153159",
            "Q244441",
            "Q5237001",
            "Q335064",
            "Q473257",
            "Q76487",
            "Q76984",
            "Q184592",
            "Q336640",
            "Q339577",
            "Q60815",
            "Q108278"
        ]
    },
    "P103": {
        "templates": [
            "The native language of [X] is [Y].",
            "[X] speaks [Y] natively.",
            "The native language of [X] is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 585,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:29:22",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Bengali",
            "Czech",
            "Danish",
            "Dutch",
            "French",
            "Hebrew",
            "Hindi",
            "Hungarian",
            "Igbo",
            "Italian",
            "Japanese",
            "Korean",
            "Malayalam",
            "Persian",
            "Polish",
            "Russian",
            "Serbian",
            "Spanish",
            "Swedish",
            "Tamil",
            "Telugu",
            "Thai",
            "Turkish",
            "Urdu",
            "Yoruba"
        ],
        "answer_space_ids": [
            "Q9610",
            "Q9056",
            "Q9035",
            "Q7411",
            "Q150",
            "Q9288",
            "Q1568",
            "Q9067",
            "Q33578",
            "Q652",
            "Q5287",
            "Q9176",
            "Q36236",
            "Q9168",
            "Q809",
            "Q7737",
            "Q9299",
            "Q1321",
            "Q9027",
            "Q5885",
            "Q8097",
            "Q9217",
            "Q256",
            "Q1617",
            "Q34311"
        ]
    },
    "P105": {
        "templates": [
            "[X] is classified at the [Y] level.",
            "[X] belongs to the [Y] taxon rank.",
            "[X] is categorized under the [Y] rank."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:29:35",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "cultivar",
            "phylum",
            "subfamily",
            "subspecies",
            "superfamily"
        ],
        "answer_space_ids": [
            "Q4886",
            "Q38348",
            "Q164280",
            "Q68947",
            "Q2136103"
        ]
    },
    "P108": {
        "templates": [
            "[X] works for [Y].",
            "[X] is employed by [Y].",
            "[X] is a worker at [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 584,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:31:54",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Apple Inc.",
            "BBC",
            "CNN",
            "Central Intelligence Agency",
            "Columbia University",
            "Duke University",
            "Federal Bureau of Investigation",
            "Google",
            "Harvard University",
            "IBM",
            "Massachusetts Institute of Technology",
            "Microsoft",
            "National Aeronautics and Space Administration",
            "Secret Intelligence Service",
            "Stanford University",
            "UNICEF",
            "United Nations",
            "University of Cambridge",
            "University of Chicago",
            "University of Edinburgh",
            "University of Glasgow",
            "University of Oxford",
            "University of Vienna",
            "Warner Bros.",
            "Yale University"
        ],
        "answer_space_ids": [
            "Q312",
            "Q9531",
            "Q48340",
            "Q37230",
            "Q49088",
            "Q168751",
            "Q8333",
            "Q95",
            "Q13371",
            "Q37156",
            "Q49108",
            "Q2283",
            "Q23548",
            "Q184560",
            "Q41506",
            "Q740308",
            "Q1065",
            "Q35794",
            "Q131252",
            "Q160302",
            "Q192775",
            "Q34433",
            "Q165980",
            "Q126399",
            "Q49112"
        ]
    },
    "P115": {
        "templates": [
            "[X]'s home venue is the [Y].",
            "The home stadium of [X] is the [Y].",
            "[X] plays their home games at the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:32:58",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Max-Morlock-Stadion",
            "Britannia Stadium",
            "Swedbank Stadion",
            "Peter Mokaba Stadium",
            "Gazprom Arena",
            "Parken Stadium",
            "Vodafone Park",
            "Tele2 Arena",
            "Riverside Stadium",
            "Heinz Field",
            "Stade Bollaert-Delelis",
            "Rocket Mortgage FieldHouse",
            "Target Center",
            "Stadion Maksimir",
            "Vivekananda Yuva Bharati Krirangan",
            "Mineir\u00e3o",
            "MKM Stadium",
            "Hrazdan Stadium",
            "Rheinpark Stadion",
            "Toumba Stadium",
            "Emirates Stadium",
            "Wembley Stadium",
            "Stade de Gen\u00e8ve",
            "Stadio Ennio Tardini",
            "Santiago Bernab\u00e9u Stadium",
            "Fratton Park",
            "Stade de Gerland",
            "Niedersachsenstadion",
            "Estadio Azteca",
            "Dean Court",
            "Est\u00e1dio do Morumbi",
            "Carrow Road",
            "Lotto Park",
            "Ahmed bin Ali Stadium",
            "Stamford Bridge",
            "Mbombela Stadium",
            "Afonso Henriques Stadium",
            "Elland Road",
            "Camp de Les Corts",
            "Arena Pantaloneta",
            "Veltins Arena",
            "La Romareda",
            "Prudential Center",
            "Johan Cruyff Arena",
            "Est\u00e1dio Nacional de Bras\u00edlia",
            "Letzigrund",
            "Leipzig Arena",
            "MetLife Stadium",
            "Scandinavium",
            "Eden Park",
            "SAP Center",
            "Rogers Arena",
            "Tokyo Dome",
            "Sinobo Stadium",
            "Empower Field at Mile High",
            "Gillette Stadium",
            "Lerkendal Stadion",
            "FNB Stadium",
            "St James\u2019 Park",
            "Donbass Arena"
        ],
        "answer_space_ids": [
            "Q152599",
            "Q500922",
            "Q867234",
            "Q187042",
            "Q722970",
            "Q33003",
            "Q14914703",
            "Q2701834",
            "Q822886",
            "Q1067148",
            "Q854122",
            "Q387157",
            "Q282675",
            "Q723603",
            "Q787124",
            "Q910370",
            "Q630160",
            "Q683493",
            "Q597004",
            "Q1141292",
            "Q163995",
            "Q128468",
            "Q215295",
            "Q610546",
            "Q164027",
            "Q619531",
            "Q1980",
            "Q152633",
            "Q320454",
            "Q619094",
            "Q821761",
            "Q123017",
            "Q262326",
            "Q401643",
            "Q171458",
            "Q187087",
            "Q1057274",
            "Q619505",
            "Q918580",
            "Q641448",
            "Q150961",
            "Q17484",
            "Q849027",
            "Q207109",
            "Q336088",
            "Q207623",
            "Q210466",
            "Q10862290",
            "Q1138447",
            "Q312411",
            "Q261863",
            "Q517318",
            "Q733748",
            "Q64858",
            "Q1046135",
            "Q373355",
            "Q1132011",
            "Q163521",
            "Q191774",
            "Q180479"
        ]
    },
    "P127": {
        "templates": [
            "[X] is owned by [Y].",
            "[Y] is the owner of [X].",
            "[X] belongs to [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 585,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:34:08",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "ABS-CBN Corporation",
            "Amtrak",
            "Berkshire Hathaway",
            "Carnival Corporation & plc",
            "Cunard Line",
            "Deutsche Bahn",
            "English Heritage",
            "Gannett",
            "General Motors",
            "Google",
            "Government of India",
            "Indian Railways",
            "Indian Space Research Organisation",
            "LVMH",
            "Long Island Rail Road",
            "Microsoft",
            "Mondel\u0113z International",
            "NBCUniversal",
            "National Park Service",
            "National Trust for Scotland",
            "Nestl\u00e9",
            "Network Rail",
            "The Walt Disney Company",
            "Unilever",
            "WarnerMedia"
        ],
        "answer_space_ids": [
            "Q287617",
            "Q23239",
            "Q217583",
            "Q1044059",
            "Q730587",
            "Q9322",
            "Q936287",
            "Q1345971",
            "Q81965",
            "Q95",
            "Q2767140",
            "Q819425",
            "Q229058",
            "Q504998",
            "Q125943",
            "Q2283",
            "Q12857502",
            "Q724759",
            "Q308439",
            "Q599997",
            "Q160746",
            "Q1501071",
            "Q7414",
            "Q157062",
            "Q191715"
        ]
    },
    "P131": {
        "templates": [
            "[X] is located in [Y].",
            "[X] is situated on the territory of [Y].",
            "[X] falls within the administrative boundaries of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:35:11",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Afghanistan",
            "Algeria",
            "Argentina",
            "Bulgaria",
            "Colombia",
            "Croatia",
            "Ecuador",
            "Egypt",
            "Hungary",
            "Indonesia",
            "Japan",
            "Nigeria",
            "Norway",
            "Pakistan",
            "Romania",
            "Serbia",
            "South Korea",
            "Sweden",
            "Switzerland",
            "Syria",
            "Turkey",
            "Ukraine",
            "the United States of America",
            "Uruguay",
            "Vatican City"
        ],
        "answer_space_ids": [
            "Q889",
            "Q262",
            "Q414",
            "Q219",
            "Q739",
            "Q224",
            "Q736",
            "Q79",
            "Q28",
            "Q252",
            "Q17",
            "Q1033",
            "Q20",
            "Q843",
            "Q218",
            "Q403",
            "Q884",
            "Q34",
            "Q39",
            "Q858",
            "Q43",
            "Q212",
            "Q30",
            "Q77",
            "Q237"
        ]
    },
    "P137": {
        "templates": [
            "[X] is operated by [Y].",
            "[Y] is the operator of [X].",
            "[X] is under the operation of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 568,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:37:30",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Airports Authority of India",
            "Amtrak",
            "Argentine Navy",
            "English Heritage",
            "European Space Agency",
            "French Navy",
            "Imperial German Navy",
            "Indian Navy",
            "Indian Railways",
            "Japan Maritime Self-Defense Force",
            "Kriegsmarine",
            "Luftwaffe",
            "MTR Corporation Limited",
            "National Aeronautics and Space Administration",
            "National Park Service",
            "People's Liberation Army Navy",
            "Regia Marina",
            "Royal Canadian Navy",
            "Royal Caribbean International",
            "Russian Navy",
            "Russian Railways",
            "Soviet Air Forces",
            "SpaceX",
            "Spanish Navy",
            "White Star Line"
        ],
        "answer_space_ids": [
            "Q3630199",
            "Q23239",
            "Q1777326",
            "Q936287",
            "Q42262",
            "Q217406",
            "Q156649",
            "Q356359",
            "Q819425",
            "Q731647",
            "Q151701",
            "Q2564009",
            "Q1479375",
            "Q23548",
            "Q308439",
            "Q755179",
            "Q855186",
            "Q25387",
            "Q929872",
            "Q465283",
            "Q660770",
            "Q921432",
            "Q193701",
            "Q676404",
            "Q320466"
        ]
    },
    "P162": {
        "templates": [
            "[X] was produced by [Y].",
            "[Y] is the producer of '[X]'.",
            "[X] is a production of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 630,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:38:37",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "\"Weird Al\" Yankovic",
            "Brian Eno",
            "Brian Wilson",
            "Calvin Harris",
            "Dave Mustaine",
            "David Bowie",
            "Dr. Dre",
            "Eminem",
            "Frank Zappa",
            "George Martin",
            "Jack White",
            "Jimmy Page",
            "Kanye West",
            "Madonna",
            "Marilyn Manson",
            "Pharrell Williams",
            "Phil Spector",
            "Prince",
            "Queen",
            "RZA",
            "Rick Rubin",
            "Stevie Wonder",
            "Timbaland",
            "Trent Reznor",
            "will.i.am"
        ],
        "answer_space_ids": [
            "Q8349",
            "Q569003",
            "Q313013",
            "Q81637",
            "Q187165",
            "Q5383",
            "Q6078",
            "Q5608",
            "Q127330",
            "Q191819",
            "Q272031",
            "Q165467",
            "Q15935",
            "Q1744",
            "Q186327",
            "Q14313",
            "Q213793",
            "Q7542",
            "Q15862",
            "Q52447",
            "Q587361",
            "Q714",
            "Q179257",
            "Q282722",
            "Q185610"
        ]
    },
    "P170": {
        "templates": [
            "[X] was created by [Y].",
            "[Y] is the creator of [X].",
            "[X] is a work of art by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 592,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:39:47",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Agatha Christie",
            "Charles Dickens",
            "Claude Monet",
            "Francisco de Goya",
            "Frank Herbert",
            "George Lucas",
            "George R. R. Martin",
            "Gian Lorenzo Bernini",
            "Isaac Asimov",
            "J. K. Rowling",
            "J.\u00a0R.\u00a0R. Tolkien",
            "Jacques-Louis David",
            "Jean Auguste Dominique Ingres",
            "Lewis Carroll",
            "Mario Puzo",
            "Matt Groening",
            "Pablo Picasso",
            "Rembrandt",
            "Ren\u00e9 Magritte",
            "Salvador Dal\u00ed",
            "Stan Lee",
            "Stephen King",
            "Titian",
            "Vincent van Gogh",
            "William Shakespeare"
        ],
        "answer_space_ids": [
            "Q35064",
            "Q5686",
            "Q296",
            "Q5432",
            "Q7934",
            "Q38222",
            "Q181677",
            "Q160538",
            "Q34981",
            "Q34660",
            "Q892",
            "Q83155",
            "Q23380",
            "Q38082",
            "Q182870",
            "Q43994",
            "Q5593",
            "Q5598",
            "Q7836",
            "Q5577",
            "Q181900",
            "Q39829",
            "Q47551",
            "Q5582",
            "Q692"
        ]
    },
    "P171": {
        "templates": [
            "The parent taxon of [X] is [Y].",
            "[X] is a taxon under the parent taxon [Y].",
            "[Y] is the parent taxon of [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:40:41",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Accipitridae",
            "Anacardiaceae",
            "Anura",
            "Apiaceae",
            "Araneae",
            "Arecaceae",
            "Arthropoda",
            "Asteraceae",
            "Canidae",
            "Cyprinidae",
            "Diptera",
            "Equidae",
            "Euphorbiaceae",
            "Formicidae",
            "Gekkonidae",
            "Lamiaceae",
            "Muscicapidae",
            "Orchidaceae",
            "Passeriformes",
            "Poaceae",
            "Rallidae",
            "Rosaceae",
            "Rubiaceae",
            "Solanaceae",
            "Theraphosidae"
        ],
        "answer_space_ids": [
            "Q25510",
            "Q156589",
            "Q53636",
            "Q145794",
            "Q1357",
            "Q14080",
            "Q1360",
            "Q25400",
            "Q25324",
            "Q35047",
            "Q25312",
            "Q165115",
            "Q156584",
            "Q7386",
            "Q15872",
            "Q53476",
            "Q200989",
            "Q25308",
            "Q25341",
            "Q43238",
            "Q26623",
            "Q46299",
            "Q156569",
            "Q134172",
            "Q213383"
        ]
    },
    "P175": {
        "templates": [
            "[X] was performed by [Y].",
            "[Y] is the performer of [X].",
            "[Y] performed [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:41:48",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Bj\u00f6rk",
            "Bob Dylan",
            "Britney Spears",
            "David Bowie",
            "Elton John",
            "Eminem",
            "Eric Clapton",
            "Frank Zappa",
            "Green Day",
            "Iron Maiden",
            "John Lennon",
            "Kanye West",
            "Madonna",
            "Michael Jackson",
            "Nicki Minaj",
            "Paul McCartney",
            "Pink Floyd",
            "Prince",
            "Red Hot Chili Peppers",
            "Rihanna",
            "Shakira",
            "Taylor Swift",
            "The Rolling Stones",
            "Tupac Shakur",
            "U2"
        ],
        "answer_space_ids": [
            "Q42455",
            "Q392",
            "Q11975",
            "Q5383",
            "Q2808",
            "Q5608",
            "Q48187",
            "Q127330",
            "Q47871",
            "Q42482",
            "Q1203",
            "Q15935",
            "Q1744",
            "Q2831",
            "Q162202",
            "Q2599",
            "Q2306",
            "Q7542",
            "Q10708",
            "Q36844",
            "Q34424",
            "Q26876",
            "Q11036",
            "Q6107",
            "Q396"
        ]
    },
    "P176": {
        "templates": [
            "[X] is produced by [Y].",
            "[Y] is the manufacturer of [X].",
            "[X] is a product of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 592,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:43:00",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Apple Inc.",
            "Armstrong Whitworth",
            "Baltic Shipyard",
            "Blohm + Voss",
            "Boeing",
            "British Motor Corporation",
            "Chantiers de l'Atlantique",
            "Chrysler",
            "Electro-Motive Diesel",
            "FN Herstal",
            "Fincantieri",
            "General Dynamics",
            "General Motors",
            "Harland and Wolff",
            "Henschel & Sohn",
            "Intel",
            "Kalashnikov Concern",
            "Lockheed Martin",
            "Meyer Werft",
            "Naval Group",
            "Newport News Shipbuilding",
            "Rheinmetall AG",
            "S.P. Korolev Rocket and Space Corporation Energia",
            "The Coca-Cola Company",
            "Vickers-Armstrongs"
        ],
        "answer_space_ids": [
            "Q312",
            "Q689159",
            "Q530989",
            "Q218715",
            "Q66",
            "Q386065",
            "Q765925",
            "Q181114",
            "Q568501",
            "Q747353",
            "Q1327429",
            "Q502940",
            "Q81965",
            "Q848977",
            "Q163580",
            "Q248",
            "Q7427495",
            "Q7240",
            "Q705377",
            "Q1227511",
            "Q82610",
            "Q161544",
            "Q763402",
            "Q3295867",
            "Q763052"
        ]
    },
    "P177": {
        "templates": [
            "The [X] crosses the [Y].",
            "The [Y] is intersected by the [X].",
            "The [X] passes through the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 585,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:43:42",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Allegheny River",
            "Columbia River",
            "Connecticut River",
            "Danube",
            "Delaware River",
            "Fraser River",
            "Hudson River",
            "Liffey",
            "Mississippi River",
            "Missouri River",
            "Ohio River",
            "Rhine",
            "River Thames",
            "River Trent",
            "Seine",
            "Tiber",
            "Vltava"
        ],
        "answer_space_ids": [
            "Q686021",
            "Q2251",
            "Q379648",
            "Q1653",
            "Q143762",
            "Q269710",
            "Q3140",
            "Q208009",
            "Q1497",
            "Q5419",
            "Q4915",
            "Q584",
            "Q19686",
            "Q19714",
            "Q1471",
            "Q13712",
            "Q131574"
        ]
    },
    "P178": {
        "templates": [
            "[X] is developed by [Y].",
            "[Y] is the developer of [X].",
            "[X] is a product developed by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 620,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:44:34",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Apple Inc.",
            "Atari, Inc.",
            "Atlus",
            "Backbone Entertainment",
            "Bandai Namco Entertainment",
            "Capcom",
            "Daybreak Game Company",
            "FromSoftware",
            "Game Freak",
            "Google",
            "HAL Laboratory",
            "IBM",
            "Konami",
            "Microsoft",
            "Midway Games",
            "Oracle",
            "Radical Entertainment",
            "Rare Ltd.",
            "Red Hat",
            "Sega AM2",
            "Sierra Entertainment",
            "Sony Interactive Entertainment",
            "Square Enix",
            "Ubisoft Montreal",
            "Visual Concepts"
        ],
        "answer_space_ids": [
            "Q312",
            "Q13409231",
            "Q780528",
            "Q389261",
            "Q1194689",
            "Q14428",
            "Q959672",
            "Q2414469",
            "Q782028",
            "Q95",
            "Q1068734",
            "Q37156",
            "Q45700",
            "Q2283",
            "Q149947",
            "Q19900",
            "Q1515682",
            "Q642707",
            "Q485593",
            "Q294587",
            "Q494614",
            "Q18594",
            "Q207784",
            "Q903621",
            "Q133482"
        ]
    },
    "P179": {
        "templates": [
            "[X] is a part of the [Y] series.",
            "[X] belongs to the [Y].",
            "The [Y] series includes [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 630,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:45:50",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "American Horror Story",
            "Better Call Saul",
            "Breaking Bad",
            "Buffy the Vampire Slayer",
            "Family Guy",
            "Futurama",
            "Game of Thrones",
            "Grey's Anatomy",
            "Homeland",
            "Mad Men",
            "Rick and Morty",
            "Seinfeld",
            "South Park",
            "SpongeBob SquarePants",
            "Star Trek: Deep Space Nine",
            "Star Trek: The Original Series",
            "The Blacklist",
            "The Office",
            "The Simpsons",
            "The Sopranos",
            "The Walking Dead",
            "The Wire",
            "The X-Files",
            "Tom and Jerry",
            "Westworld"
        ],
        "answer_space_ids": [
            "Q53922",
            "Q14925221",
            "Q1079",
            "Q183513",
            "Q5930",
            "Q73622",
            "Q23572",
            "Q438406",
            "Q23594",
            "Q223977",
            "Q15659308",
            "Q23733",
            "Q16538",
            "Q83279",
            "Q108774",
            "Q1077",
            "Q13148212",
            "Q23831",
            "Q886",
            "Q23628",
            "Q232737",
            "Q478360",
            "Q2744",
            "Q131144",
            "Q17572811"
        ]
    },
    "P185": {
        "templates": [
            "[X] was a doctoral student of [Y].",
            "[Y] was the doctoral advisor of [X].",
            "[X] pursued a doctoral degree under [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:47:38",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Friedrich W\u00f6hler",
            "Gaston Bachelard",
            "Alfred Tarski",
            "James D. Watson",
            "Ludwig Wittgenstein",
            "Theodor Svedberg",
            "Charles Hard Townes",
            "Karl Popper",
            "Victor Grignard",
            "Niels Bohr",
            "Richard Dawkins",
            "Stanis\u0142aw Ulam",
            "Joseph-Louis Lagrange",
            "Joseph Plateau",
            "Bernhard Schlink",
            "Andrea M. Ghez",
            "Robert Brown",
            "John B. Goodenough",
            "Abraham Gottlob Werner",
            "Ejnar Hertzsprung",
            "Tullio Levi-Civita",
            "Santiago Ram\u00f3n y Cajal",
            "Henri Moissan",
            "Stanford Moore",
            "Lodovico Ferrari",
            "Nicolaus Copernicus",
            "Georges Dum\u00e9zil",
            "Marcel Mauss",
            "Carl Menger",
            "Justus von Liebig",
            "Sophus Lie",
            "Johannes Stark",
            "Melvin Schwartz",
            "Konstantin Novoselov",
            "Oliver E. Williamson",
            "Pietro Pomponazzi",
            "Vincenzo Viviani",
            "Giovanni Schiaparelli",
            "Arthur Cecil Pigou",
            "Haldan Keffer Hartline",
            "Wilhelm Wundt",
            "Brian Cox",
            "Jonas Salk",
            "Robert Hooke",
            "J\u00f6ns Jacob Berzelius",
            "Benedict Anderson",
            "Har Gobind Khorana",
            "Georges Lema\u00eetre",
            "Charles Glover Barkla",
            "Williamina Fleming",
            "Jordan Peterson",
            "Georg Joachim Rheticus",
            "Tasuku Honjo",
            "Jacob Bernoulli",
            "James Rothman",
            "Fraser Stoddart",
            "Emil Abderhalden",
            "Edward Mills Purcell",
            "Clifford Shull",
            "Christophoros A. Pissarides"
        ],
        "answer_space_ids": [
            "Q58575",
            "Q270800",
            "Q207534",
            "Q83333",
            "Q9391",
            "Q186391",
            "Q184566",
            "Q81244",
            "Q104582",
            "Q7085",
            "Q44461",
            "Q234357",
            "Q80222",
            "Q379993",
            "Q76699",
            "Q493956",
            "Q155764",
            "Q906529",
            "Q58751",
            "Q295099",
            "Q353438",
            "Q150526",
            "Q102804",
            "Q110952",
            "Q310783",
            "Q619",
            "Q310590",
            "Q295393",
            "Q84177",
            "Q16571",
            "Q30769",
            "Q57092",
            "Q189741",
            "Q106494",
            "Q232062",
            "Q318787",
            "Q318037",
            "Q14281",
            "Q313034",
            "Q309879",
            "Q75814",
            "Q463581",
            "Q200101",
            "Q46830",
            "Q151911",
            "Q212993",
            "Q107462",
            "Q12998",
            "Q160522",
            "Q284180",
            "Q6276882",
            "Q93588",
            "Q2395341",
            "Q122392",
            "Q444270",
            "Q376243",
            "Q123557",
            "Q183270",
            "Q201506",
            "Q109582"
        ]
    },
    "P190": {
        "templates": [
            "[X] and [Y] are twin cities.",
            "[X] has a partnership with [Y].",
            "[X] is a sister city of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:48:33",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Klagenfurt",
            "Andorra la Vella",
            "Ottawa",
            "Oviedo",
            "Lahore",
            "Calais",
            "Dodoma",
            "Karlsruhe",
            "Bangkok",
            "Nuuk",
            "Rennes",
            "Bursa",
            "Besan\u00e7on",
            "San Jos\u00e9",
            "Tangier",
            "Hamburg",
            "Kaunas",
            "Omaha",
            "Alicante",
            "Harbin",
            "Debrecen",
            "\u0141obez",
            "Wuppertal",
            "Ostrava",
            "Warsaw",
            "Herat",
            "Beijing",
            "Ljubljana",
            "Seattle",
            "Kigali",
            "Manila",
            "Buffalo",
            "Dushanbe",
            "Potenza",
            "Oakland",
            "New Orleans",
            "Osasco",
            "Surabaya",
            "Nagasaki",
            "Monz\u00f3n",
            "Reims",
            "Tulsa",
            "Batumi",
            "Sochi",
            "Montreal",
            "Monaco",
            "Banjul",
            "Szeged",
            "Harare",
            "Durban",
            "Bremen",
            "Girona",
            "Des Moines",
            "Wiesbaden",
            "Vientiane",
            "Winnipeg",
            "Columbus",
            "Tirana",
            "Lisbon",
            "Timbuktu"
        ],
        "answer_space_ids": [
            "Q41753",
            "Q1863",
            "Q1930",
            "Q14317",
            "Q11739",
            "Q6454",
            "Q3866",
            "Q1040",
            "Q1861",
            "Q226",
            "Q647",
            "Q40738",
            "Q37776",
            "Q3070",
            "Q126148",
            "Q1055",
            "Q4115712",
            "Q43199",
            "Q11959",
            "Q42956",
            "Q79880",
            "Q196163",
            "Q2107",
            "Q8385",
            "Q270",
            "Q45313",
            "Q956",
            "Q437",
            "Q5083",
            "Q3859",
            "Q1461",
            "Q40435",
            "Q9365",
            "Q3543",
            "Q17042",
            "Q34404",
            "Q4035",
            "Q11462",
            "Q38234",
            "Q5123",
            "Q41876",
            "Q44989",
            "Q25475",
            "Q39420",
            "Q340",
            "Q235",
            "Q3726",
            "Q81581",
            "Q3921",
            "Q5468",
            "Q24879",
            "Q7038",
            "Q39709",
            "Q1721",
            "Q9326",
            "Q2135",
            "Q16567",
            "Q19689",
            "Q597",
            "Q9427"
        ]
    },
    "P206": {
        "templates": [
            "[X] is next to the [Y].",
            "[X] is situated on the shores of the [Y].",
            "[X] can be found adjacent to the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:50:56",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Adriatic Sea",
            "Aegean Sea",
            "Baltic Sea",
            "Bering Sea",
            "Caribbean Sea",
            "Danube",
            "Dnieper River",
            "English Channel",
            "Gulf of Mexico",
            "Indian Ocean",
            "Inn",
            "Ionian Sea",
            "Irish Sea",
            "Lake Ontario",
            "Mississippi River",
            "Moselle",
            "North Sea",
            "Persian Gulf",
            "Philippine Sea",
            "Rhine",
            "River Thames",
            "Seine",
            "South China Sea",
            "Southern Ocean",
            "Tyrrhenian Sea"
        ],
        "answer_space_ids": [
            "Q13924",
            "Q34575",
            "Q545",
            "Q44725",
            "Q1247",
            "Q1653",
            "Q40855",
            "Q34640",
            "Q12630",
            "Q1239",
            "Q14369",
            "Q37495",
            "Q41735",
            "Q1062",
            "Q1497",
            "Q1667",
            "Q1693",
            "Q34675",
            "Q159183",
            "Q584",
            "Q19686",
            "Q1471",
            "Q37660",
            "Q7354",
            "Q38882"
        ]
    },
    "P272": {
        "templates": [
            "[Y] produced [X].",
            "[X] is produced by [Y].",
            "[X] is a production of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:52:58",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "20th Century Studios",
            "ABC Signature",
            "Amblin Entertainment",
            "Castle Rock Entertainment",
            "Columbia Pictures",
            "Dimension Films",
            "DreamWorks Animation",
            "Endemol",
            "Fremantle",
            "HBO",
            "Lionsgate",
            "Metro-Goldwyn-Mayer",
            "Miramax",
            "Netflix",
            "New Line Cinema",
            "Paramount Pictures",
            "Pixar",
            "Searchlight Pictures",
            "Sony Pictures Television Studios",
            "Studio Ghibli",
            "T-Series",
            "The Walt Disney Company",
            "Touchstone Pictures",
            "TriStar Pictures",
            "Universal Pictures"
        ],
        "answer_space_ids": [
            "Q434841",
            "Q287218",
            "Q457893",
            "Q622848",
            "Q186941",
            "Q908662",
            "Q500088",
            "Q851184",
            "Q520445",
            "Q23633",
            "Q515869",
            "Q179200",
            "Q465449",
            "Q907311",
            "Q79202",
            "Q159846",
            "Q127552",
            "Q953040",
            "Q652390",
            "Q182950",
            "Q7667850",
            "Q7414",
            "Q497155",
            "Q651454",
            "Q168383"
        ]
    },
    "P291": {
        "templates": [
            "The place of publication for [X] was [Y].",
            "[X] was published in [Y].",
            "[X] got published in [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 609,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:53:25",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Australia",
            "Brazil",
            "Canada",
            "Finland",
            "France",
            "Indonesia",
            "Italy",
            "Japan",
            "Mexico",
            "the Netherlands",
            "Norway",
            "Poland",
            "South Korea",
            "Spain",
            "Sweden",
            "the United Kingdom",
            "the United States of America"
        ],
        "answer_space_ids": [
            "Q408",
            "Q155",
            "Q16",
            "Q33",
            "Q142",
            "Q252",
            "Q38",
            "Q17",
            "Q96",
            "Q55",
            "Q20",
            "Q36",
            "Q884",
            "Q29",
            "Q34",
            "Q145",
            "Q30"
        ]
    },
    "P344": {
        "templates": [
            "[X] had [Y] as its director of photography.",
            "[Y] was the director of photography for [X].",
            "The director of photography for [X] is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 592,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:54:38",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Adam Greenberg",
            "Anthony Dod Mantle",
            "Dante Spinotti",
            "Dean Cundey",
            "Janusz Kami\u0144ski",
            "Javier Aguirresarobe",
            "John Seale",
            "Mark Irwin",
            "Michael Ballhaus",
            "Newton Thomas Sigel",
            "Peter Deming",
            "Phedon Papamichael",
            "Philippe Rousselot",
            "Robert Elswit",
            "Robert Richardson",
            "Robert Yeoman",
            "Roger Deakins",
            "Russell Carpenter",
            "Santosh Sivan",
            "Sven Nykvist",
            "Tak Fujimoto",
            "Tonino Delli Colli",
            "Vilmos Zsigmond",
            "Vittorio Storaro",
            "William A. Fraker"
        ],
        "answer_space_ids": [
            "Q349588",
            "Q573164",
            "Q179657",
            "Q497036",
            "Q365230",
            "Q1366385",
            "Q918558",
            "Q1551917",
            "Q62547",
            "Q1367452",
            "Q1462878",
            "Q978315",
            "Q750718",
            "Q279100",
            "Q364017",
            "Q551828",
            "Q460277",
            "Q497075",
            "Q2615641",
            "Q312290",
            "Q488925",
            "Q1567717",
            "Q963628",
            "Q363413",
            "Q489559"
        ]
    },
    "P364": {
        "templates": [
            "The original language of [X] is [Y].",
            "[X] was originally created in [Y].",
            "[Y] is the language of [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 603,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:55:43",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Bengali",
            "Cantonese",
            "Danish",
            "Dutch",
            "Filipino",
            "Finnish",
            "French",
            "Gujarati",
            "Hindi",
            "Italian",
            "Japanese",
            "Kannada",
            "Korean",
            "Malayalam",
            "Norwegian",
            "Polish",
            "Punjabi",
            "Russian",
            "Spanish",
            "Swedish",
            "Tamil",
            "Telugu",
            "Thai",
            "Turkish",
            "Urdu"
        ],
        "answer_space_ids": [
            "Q9610",
            "Q9186",
            "Q9035",
            "Q7411",
            "Q33298",
            "Q1412",
            "Q150",
            "Q5137",
            "Q1568",
            "Q652",
            "Q5287",
            "Q33673",
            "Q9176",
            "Q36236",
            "Q9043",
            "Q809",
            "Q58635",
            "Q7737",
            "Q1321",
            "Q9027",
            "Q5885",
            "Q8097",
            "Q9217",
            "Q256",
            "Q1617"
        ]
    },
    "P403": {
        "templates": [
            "The [X] flows into the [Y].",
            "The [X] eventually leads to the [Y].",
            "The [X] empties into the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:56:22",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Adriatic Sea",
            "Arabian Sea",
            "Baltic Sea",
            "Bass Strait",
            "Bay of Bengal",
            "Black Sea",
            "Caribbean Sea",
            "Coral Sea",
            "English Channel",
            "Gulf of Mexico",
            "Ionian Sea",
            "Irish Sea",
            "Lake Superior",
            "North Sea",
            "Tasman Sea",
            "Tyrrhenian Sea"
        ],
        "answer_space_ids": [
            "Q13924",
            "Q58705",
            "Q545",
            "Q171846",
            "Q38684",
            "Q166",
            "Q1247",
            "Q82931",
            "Q34640",
            "Q12630",
            "Q37495",
            "Q41735",
            "Q1066",
            "Q1693",
            "Q33254",
            "Q38882"
        ]
    },
    "P412": {
        "templates": [
            "[X]'s voice type is [Y].",
            "[X] is known for their [Y] voice.",
            "The voice type of [X] is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:56:34",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Heldentenor",
            "bass-baritone",
            "coloratura soprano",
            "contralto",
            "countertenor",
            "mezzo-soprano"
        ],
        "answer_space_ids": [
            "Q1601762",
            "Q810480",
            "Q58192",
            "Q37137",
            "Q223166",
            "Q186506"
        ]
    },
    "P413": {
        "templates": [
            "[X] plays in [Y] position.",
            "[X] specialized in the [Y] position.",
            "[X] plays as [Y]"
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 612,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:57:37",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "catcher",
            "center fielder",
            "cornerback",
            "defensive end",
            "defensive tackle",
            "first baseman",
            "fullback",
            "goalkeeper",
            "halfback",
            "left fielder",
            "linebacker",
            "placekicker",
            "point guard",
            "power forward",
            "quarterback",
            "right fielder",
            "running back",
            "safety",
            "second baseman",
            "shooting guard",
            "shortstop",
            "small forward",
            "starting pitcher",
            "third baseman",
            "tight end"
        ],
        "answer_space_ids": [
            "Q1050571",
            "Q5059480",
            "Q869161",
            "Q903354",
            "Q2550304",
            "Q1326154",
            "Q5508224",
            "Q201330",
            "Q589410",
            "Q1149868",
            "Q528145",
            "Q1638113",
            "Q212413",
            "Q462471",
            "Q622747",
            "Q1149560",
            "Q912985",
            "Q24994",
            "Q1368195",
            "Q273199",
            "Q1143358",
            "Q308879",
            "Q772148",
            "Q1368170",
            "Q1153176"
        ]
    },
    "P427": {
        "templates": [
            "[X] is a taxonomic type of [Y].",
            "The taxonomic type of [X] is [Y].",
            "[X] is a [Y] in taxonomy."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:58:36",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Butterfly blenny",
            "Smearwort",
            "grass snake",
            "Alangium",
            "Map lichen",
            "black cardamom",
            "Big-eared swamp rat",
            "Haloragis",
            "Laurus nobilis",
            "Eurasian Blackcap",
            "Hepatitis B virus",
            "Claviceps purpurea",
            "Plasmodium falciparum",
            "Borago",
            "Common milkwort",
            "Asilidae",
            "Loranthus",
            "summer truffle",
            "Dismorphia",
            "Pittosporum",
            "Rubella virus",
            "Chestnut blight",
            "Detarium",
            "Streptococcus",
            "Great yellow gentian",
            "Rhipsalis",
            "Monkey goby",
            "Bruchus",
            "raccoon",
            "blue mussel",
            "Ceratophyllum",
            "European seabass",
            "Cercis",
            "Giant orchid",
            "Fowlpox virus",
            "Erythroxylum",
            "Dialium",
            "Red dead-nettle",
            "Drosophila",
            "Thermoproteus",
            "Timothy-grass",
            "murine leukemia virus",
            "Common bladderwort",
            "Mazus",
            "House Sparrow",
            "Spirillum",
            "sheathed woodtuft",
            "Caesalpinia",
            "Neottia nidus-avis",
            "Reticulate whipray",
            "Northern common cuscus",
            "Mytilus",
            "Eimeria",
            "Pyrodictium",
            "Ruta graveolens",
            "Bactrian camel",
            "Acanthamoeba",
            "tobacco mosaic virus",
            "Parvovirus B19",
            "Erebus"
        ],
        "answer_space_ids": [
            "Q1474934",
            "Q2861412",
            "Q170713",
            "Q311949",
            "Q1365267",
            "Q1369048",
            "Q1763296",
            "Q2617536",
            "Q26006",
            "Q188446",
            "Q6844",
            "Q217227",
            "Q311383",
            "Q149122",
            "Q162905",
            "Q837089",
            "Q163517",
            "Q74692",
            "Q602737",
            "Q158896",
            "Q701609",
            "Q1010057",
            "Q310991",
            "Q190161",
            "Q158572",
            "Q132296",
            "Q924985",
            "Q2926499",
            "Q121439",
            "Q27855",
            "Q21795",
            "Q217129",
            "Q29033",
            "Q3006235",
            "Q571218",
            "Q158138",
            "Q5236308",
            "Q157619",
            "Q312154",
            "Q863318",
            "Q256508",
            "Q673848",
            "Q157384",
            "Q136934",
            "Q14683",
            "Q69598",
            "Q732640",
            "Q608215",
            "Q157441",
            "Q1254948",
            "Q209996",
            "Q21132",
            "Q795375",
            "Q1046911",
            "Q25062",
            "Q132922",
            "Q1152218",
            "Q332874",
            "Q933694",
            "Q1366773"
        ]
    },
    "P449": {
        "templates": [
            "[X] was originally aired on [Y].",
            "[X] was originally broadcasted by [Y].",
            "[X] debuted on [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 13:59:43",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "AMC",
            "Amazon Prime Video",
            "BBC One",
            "BBC Two",
            "CBS",
            "Cartoon Network",
            "Comedy Central",
            "Disney Channel",
            "FX",
            "Fox Broadcasting Company",
            "Freeform",
            "Fuji Television",
            "HBO",
            "Hulu",
            "JTBC",
            "KBS2",
            "Korean Broadcasting System",
            "Netflix",
            "Nickelodeon",
            "Public Broadcasting Service",
            "Showtime",
            "TV Tokyo",
            "The CW",
            "USA Network",
            "tvN"
        ],
        "answer_space_ids": [
            "Q294660",
            "Q4740856",
            "Q191472",
            "Q216108",
            "Q43380",
            "Q708290",
            "Q131439",
            "Q178837",
            "Q651228",
            "Q166419",
            "Q287149",
            "Q744800",
            "Q23633",
            "Q1630304",
            "Q213097",
            "Q624509",
            "Q498825",
            "Q907311",
            "Q154958",
            "Q215616",
            "Q23589",
            "Q734663",
            "Q212252",
            "Q248713",
            "Q333424"
        ]
    },
    "P463": {
        "templates": [
            "[X] is member of the [Y].",
            "[X] is affiliated with the [Y].",
            "[X] is part of the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 584,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:00:56",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Acad\u00e9mie Fran\u00e7aise",
            "Acad\u00e9mie des beaux-arts",
            "American Association for the Advancement of Science",
            "British Academy",
            "Cyprus Football Association",
            "European Broadcasting Union",
            "European People's Party",
            "Filiki Eteria",
            "German Academy of Sciences Leopoldina",
            "Holy Roman Empire",
            "International Olympic Committee",
            "International Workingmen's Association",
            "Ku Klux Klan",
            "Magnum Photos",
            "Memory of the World",
            "NAACP",
            "Parliamentary Assembly of the Council of Europe",
            "Peace Corps",
            "Provisional Irish Republican Army",
            "Romanian Academy",
            "Royal Shakespeare Company",
            "Schutzstaffel",
            "Sturmabteilung",
            "United States Army Special Forces",
            "freemasonry"
        ],
        "answer_space_ids": [
            "Q161806",
            "Q337531",
            "Q40358",
            "Q723551",
            "Q473248",
            "Q166400",
            "Q208242",
            "Q634186",
            "Q543804",
            "Q12548",
            "Q40970",
            "Q183725",
            "Q47131",
            "Q372899",
            "Q473858",
            "Q502044",
            "Q939743",
            "Q458620",
            "Q504628",
            "Q901677",
            "Q1146254",
            "Q44687",
            "Q150793",
            "Q482421",
            "Q41726"
        ]
    },
    "P466": {
        "templates": [
            "[X] is occupied by [Y].",
            "The occupant of [X] is [Y].",
            "[Y] occupies [X]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:01:53",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "John III Sobieski",
            "G\u00f3rnik Zabrze",
            "Brooklyn Nets",
            "Rainer Maria Rilke",
            "Lutheranism",
            "Crystal Palace F.C.",
            "Club Atl\u00e9tico Osasuna",
            "Vijayanagara Gadariya  Empire",
            "University of Helsinki",
            "Franklin Delano Roosevelt",
            "Althing",
            "Central Intelligence Agency",
            "FK S\u016bduva Marijampol\u0117",
            "Manchester City F.C.",
            "PSV Eindhoven",
            "Phoenix Suns",
            "Internet Archive",
            "San Antonio Spurs",
            "Province of Venice",
            "Cagliari Calcio",
            "FCSB",
            "Juventus F.C.",
            "Aston Villa F.C.",
            "Isaac Newton",
            "Commonwealth of Nations",
            "Victor Hugo",
            "Adolf Hitler",
            "Miami Heat",
            "PFC CSKA Moscow",
            "Everton F.C.",
            "Society of Jesus",
            "1972 Winter Olympics",
            "FC Basel",
            "Parma Calcio 1913",
            "S\u00e3o Paulo FC",
            "Charlotte Hornets",
            "FC Twente",
            "FC Lokomotiv Moscow",
            "FC Shakhtar Donetsk",
            "Bolton Wanderers F.C.",
            "Stanford University",
            "Real Betis Balompi\u00e9",
            "Portland Trail Blazers",
            "1. FC K\u00f6ln",
            "Sacramento Kings",
            "Arsenal F.C.",
            "Blackburn Rovers F.C.",
            "Federal Security Service",
            "Jefferson Davis",
            "Palermo FC",
            "S.C. Corinthians Paulista",
            "Atlanta Hawks",
            "Southampton F.C.",
            "Norwich City F.C.",
            "Joachim Murat",
            "Swansea City A.F.C.",
            "Villarreal C.F.",
            "Amenhotep III",
            "Elizabeth II",
            "SC Freiburg"
        ],
        "answer_space_ids": [
            "Q53454",
            "Q134255",
            "Q572134",
            "Q76483",
            "Q75809",
            "Q19467",
            "Q10286",
            "Q167639",
            "Q28695",
            "Q8007",
            "Q131279",
            "Q37230",
            "Q757104",
            "Q50602",
            "Q11938",
            "Q164177",
            "Q461",
            "Q159729",
            "Q16310",
            "Q1900",
            "Q179658",
            "Q1422",
            "Q18711",
            "Q935",
            "Q7785",
            "Q535",
            "Q352",
            "Q169138",
            "Q176371",
            "Q5794",
            "Q36380",
            "Q9646",
            "Q189671",
            "Q2693",
            "Q38568",
            "Q163480",
            "Q19603",
            "Q29115",
            "Q172969",
            "Q19451",
            "Q41506",
            "Q8723",
            "Q167253",
            "Q104770",
            "Q166105",
            "Q9617",
            "Q19446",
            "Q58792",
            "Q162269",
            "Q2674",
            "Q35933",
            "Q159893",
            "Q18732",
            "Q18721",
            "Q151173",
            "Q18659",
            "Q12297",
            "Q42606",
            "Q9682",
            "Q106394"
        ]
    },
    "P509": {
        "templates": [
            "[X] died from [Y].",
            "[X]'s death was caused by [Y].",
            "[X] died due to [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 610,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:03:52",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Alzheimer's disease",
            "Parkinson's disease",
            "amyotrophic lateral sclerosis",
            "asphyxia",
            "breast cancer",
            "cardiac arrest",
            "colorectal cancer",
            "diabetes",
            "heart failure",
            "kidney failure",
            "leukemia",
            "liver cancer",
            "liver cirrhosis",
            "lung cancer",
            "lymphoma",
            "myocardial infarction",
            "ovarian cancer",
            "pancreatic cancer",
            "peritonitis",
            "prostate cancer",
            "pulmonary emphysema",
            "sepsis",
            "stomach cancer",
            "stroke",
            "tuberculosis"
        ],
        "answer_space_ids": [
            "Q11081",
            "Q11085",
            "Q206901",
            "Q193840",
            "Q128581",
            "Q202837",
            "Q188874",
            "Q12206",
            "Q181754",
            "Q476921",
            "Q29496",
            "Q623031",
            "Q147778",
            "Q47912",
            "Q208414",
            "Q12152",
            "Q172341",
            "Q212961",
            "Q223102",
            "Q181257",
            "Q188605",
            "Q183134",
            "Q189588",
            "Q12202",
            "Q12204"
        ]
    },
    "P610": {
        "templates": [
            "The highest point in [X] is [Y].",
            "[Y] is the highest peak in [X].",
            "[X] has its highest point at [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:04:49",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Monte Pissis",
            "Brandberg",
            "Auk\u0161tojas Hill",
            "Magli\u0107",
            "Puy de D\u00f4me",
            "Phnom Aural",
            "Mulanje Massif",
            "Vinson Massif",
            "Mount Pel\u00e9e",
            "Mount Olympus",
            "Victoria Peak",
            "Haleakal\u0101",
            "Suur Munam\u00e4gi",
            "Volc\u00e1n Wolf",
            "Antisana volcano",
            "Meron",
            "Mount Emei",
            "Gro\u00dfvenediger",
            "Mount Karthala",
            "Tronador",
            "Mousa Ali",
            "Tatamailau",
            "Aconcagua",
            "Table Mountain",
            "Jebel Shams",
            "Teide",
            "Byrranga Mountains",
            "Yr Wyddfa",
            "Bogd Khan Mountain",
            "Nanda Devi",
            "Jbel Toubkal",
            "Hallasan",
            "Thabana Ntlenyana",
            "Peak Pobeda, Sakha",
            "Barre des \u00c9crins",
            "Mount Elbrus",
            "Gerlachovsk\u00fd \u0161t\u00edt",
            "Cayambe volcano",
            "Llullaillaco",
            "Bobotov Kuk",
            "Tirich Mir",
            "Grossglockner",
            "Pico Bol\u00edvar",
            "Volc\u00e1n Bar\u00fa",
            "Mount Fairweather",
            "Nevado Sajama",
            "Babia G\u00f3ra",
            "Qurnat as Sawda'",
            "Pico da Neblina",
            "Yerupaj\u00e1",
            "Sn\u011b\u017eka",
            "Ojos del Salado",
            "Wildspitze",
            "Khazret Sultan",
            "Finsteraarhorn",
            "Monte Cinto",
            "Beerenberg",
            "Pico Turquino",
            "Mount Scenery",
            "K2"
        ],
        "answer_space_ids": [
            "Q586212",
            "Q897834",
            "Q771431",
            "Q837723",
            "Q607372",
            "Q539772",
            "Q1510436",
            "Q163758",
            "Q76309",
            "Q819979",
            "Q17541",
            "Q515719",
            "Q504991",
            "Q1376373",
            "Q14082",
            "Q540520",
            "Q134927",
            "Q697907",
            "Q527548",
            "Q422835",
            "Q1951029",
            "Q1539961",
            "Q39739",
            "Q213360",
            "Q1261915",
            "Q38954",
            "Q804012",
            "Q217142",
            "Q654413",
            "Q213262",
            "Q503433",
            "Q494645",
            "Q733132",
            "Q745231",
            "Q30480",
            "Q43105",
            "Q81213",
            "Q754734",
            "Q214916",
            "Q671897",
            "Q207132",
            "Q3388",
            "Q213704",
            "Q594726",
            "Q1544340",
            "Q272593",
            "Q595780",
            "Q311330",
            "Q739484",
            "Q529797",
            "Q617511",
            "Q233836",
            "Q679277",
            "Q519822",
            "Q15127",
            "Q1415428",
            "Q814113",
            "Q1145743",
            "Q1301834",
            "Q43512"
        ]
    },
    "P611": {
        "templates": [
            "[X] is a member of the [Y].",
            "[X] belongs to the [Y].",
            "[X] is part of the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 585,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:05:35",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Augustinians",
            "Benedictines",
            "Carmelites",
            "Carthusian Order",
            "Congregation of the Mission",
            "Congregation of the Most Holy Redeemer",
            "Conventual Franciscans",
            "Divine Word Missionaries",
            "Dominican Order",
            "Gelug",
            "Holy Ghost Fathers",
            "Institute of the Brothers of the Christian Schools",
            "Oratory of Saint Philip Neri",
            "Order of Cistercians of the Strict Observance",
            "Order of Friars Minor Capuchin",
            "Order of Hospitallers",
            "Order of Poor Clerks Regular of the Mother of God of the Pious Schools",
            "Order of the Minims",
            "Passionists",
            "Poor Clares",
            "Premonstratensians",
            "Salesians of Don Bosco",
            "Servite Order",
            "Society of Jesus",
            "Third Order of Saint Francis"
        ],
        "answer_space_ids": [
            "Q214528",
            "Q131132",
            "Q186277",
            "Q220979",
            "Q849726",
            "Q751148",
            "Q692799",
            "Q696656",
            "Q131479",
            "Q319218",
            "Q687562",
            "Q138579",
            "Q247132",
            "Q276223",
            "Q124862",
            "Q187549",
            "Q273894",
            "Q1367736",
            "Q774589",
            "Q733658",
            "Q339332",
            "Q223659",
            "Q615923",
            "Q36380",
            "Q9295862"
        ]
    },
    "P641": {
        "templates": [
            "[X] is associated with [Y].",
            "[X] participates in [Y].",
            "The sport [X] was playing is [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 584,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:06:38",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "American football",
            "Muay Thai",
            "auto racing",
            "badminton",
            "baseball",
            "beach volleyball",
            "bodybuilding",
            "esports",
            "figure skating",
            "freestyle wrestling",
            "golf",
            "horse racing",
            "karate",
            "kickboxing",
            "mixed martial arts",
            "motorcycle sport",
            "mountaineering",
            "professional wrestling",
            "skateboarding",
            "ski jumping",
            "snooker",
            "snowboarding",
            "sumo",
            "taekwondo",
            "weightlifting"
        ],
        "answer_space_ids": [
            "Q41323",
            "Q120931",
            "Q5386",
            "Q7291",
            "Q5369",
            "Q4543",
            "Q124100",
            "Q300920",
            "Q38108",
            "Q327223",
            "Q5377",
            "Q187916",
            "Q11419",
            "Q178678",
            "Q114466",
            "Q328716",
            "Q36908",
            "Q131359",
            "Q842284",
            "Q7718",
            "Q11015",
            "Q178131",
            "Q40561",
            "Q36389",
            "Q83462"
        ]
    },
    "P676": {
        "templates": [
            "The lyrics of [X] were written by [Y].",
            "[X]'s lyrics were penned by [Y].",
            "The song '[X]' features lyrics by [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:09:34",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Billie Joe Armstrong",
            "Bob Dylan",
            "Bono",
            "Bruno Mars",
            "David Bowie",
            "Dolly Parton",
            "Dr. Dre",
            "Ed Sheeran",
            "Eminem",
            "Freddie Mercury",
            "George Michael",
            "Irving Berlin",
            "John Lennon",
            "Kurt Cobain",
            "Madonna",
            "Michael Jackson",
            "Paul McCartney",
            "Paul Simon",
            "Phil Collins",
            "Prince",
            "Roger Waters",
            "Sia",
            "Stevie Wonder",
            "Sting",
            "Taylor Swift"
        ],
        "answer_space_ids": [
            "Q712592",
            "Q392",
            "Q834621",
            "Q1450",
            "Q5383",
            "Q180453",
            "Q6078",
            "Q47447",
            "Q5608",
            "Q15869",
            "Q130311",
            "Q128746",
            "Q1203",
            "Q8446",
            "Q1744",
            "Q2831",
            "Q2599",
            "Q4028",
            "Q144622",
            "Q7542",
            "Q180861",
            "Q181484",
            "Q714",
            "Q483203",
            "Q26876"
        ]
    },
    "P1303": {
        "templates": [
            "[X] plays [Y].",
            "[X] is known for playing [Y].",
            "[X] is a [Y] player."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 616,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:10:53",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "accordion",
            "acoustic guitar",
            "bagpipes",
            "banjo",
            "cello",
            "clarinet",
            "double bass",
            "drum kit",
            "electric guitar",
            "electronic keyboard",
            "fiddle",
            "harmonica",
            "harpsichord",
            "jazz violin",
            "mandolin",
            "oud",
            "pipe organ",
            "reed organ",
            "sampler",
            "saxophone",
            "sitar",
            "synthesizer",
            "trombone",
            "ukulele",
            "viola"
        ],
        "answer_space_ids": [
            "Q79838",
            "Q31561",
            "Q8347",
            "Q258896",
            "Q8371",
            "Q8343",
            "Q80019",
            "Q128309",
            "Q78987",
            "Q1343007",
            "Q510487",
            "Q51290",
            "Q81982",
            "Q1684562",
            "Q302497",
            "Q191000",
            "Q281460",
            "Q12460259",
            "Q320002",
            "Q9798",
            "Q229205",
            "Q163829",
            "Q8350",
            "Q61285",
            "Q80284"
        ]
    },
    "P1376": {
        "templates": [
            "[X] is the capital of [Y].",
            "[Y] has its governmental seat in [X].",
            "[X] serves as the capital of [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:11:44",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Republic of the Congo",
            "Sri Lanka",
            "Lebanon",
            "Mozambique",
            "Lesotho",
            "Czech Republic",
            "Eswatini",
            "Somalia",
            "Benin",
            "Japan",
            "Tanzania",
            "Argentina",
            "Armenia",
            "Antigua and Barbuda",
            "Ghana",
            "Djibouti",
            "Grenada",
            "Equatorial Guinea",
            "Bolivia",
            "Azerbaijan",
            "Zimbabwe",
            "Bhutan",
            "Poland",
            "Central African Republic",
            "Thailand",
            "Cuba",
            "Nigeria",
            "Mexico",
            "Afghanistan",
            "Saint Kitts and Nevis",
            "Ivory Coast",
            "Barbados",
            "North Korea",
            "Bosnia and Herzegovina",
            "Gabon",
            "Guyana",
            "India",
            "Jordan",
            "Madagascar",
            "Liechtenstein",
            "Zambia",
            "the Philippines",
            "Monaco",
            "Saint Lucia",
            "Latvia",
            "Georgia",
            "Slovakia",
            "Liberia",
            "Belarus",
            "Venezuela",
            "Suriname",
            "Algeria",
            "Uruguay",
            "the Bahamas",
            "Laos",
            "Haiti",
            "Tuvalu",
            "Sudan",
            "Mali",
            "Oman"
        ],
        "answer_space_ids": [
            "Q971",
            "Q854",
            "Q822",
            "Q1029",
            "Q1013",
            "Q213",
            "Q1050",
            "Q1045",
            "Q962",
            "Q17",
            "Q924",
            "Q414",
            "Q399",
            "Q781",
            "Q117",
            "Q977",
            "Q769",
            "Q983",
            "Q750",
            "Q227",
            "Q954",
            "Q917",
            "Q36",
            "Q929",
            "Q869",
            "Q241",
            "Q1033",
            "Q96",
            "Q889",
            "Q763",
            "Q1008",
            "Q244",
            "Q423",
            "Q225",
            "Q1000",
            "Q734",
            "Q668",
            "Q810",
            "Q1019",
            "Q347",
            "Q953",
            "Q928",
            "Q235",
            "Q760",
            "Q211",
            "Q230",
            "Q214",
            "Q1014",
            "Q184",
            "Q717",
            "Q730",
            "Q262",
            "Q77",
            "Q778",
            "Q819",
            "Q790",
            "Q672",
            "Q1049",
            "Q912",
            "Q842"
        ]
    },
    "P1412": {
        "templates": [
            "[X] used to communicate in [Y].",
            "[Y] is the language used by [X] .",
            "[X] is proficient in [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:12:54",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Ancient Greek",
            "Arabic",
            "Bengali",
            "Czech",
            "Dutch",
            "Hebrew",
            "Hindi",
            "Italian",
            "Japanese",
            "Kannada",
            "Korean",
            "Malayalam",
            "Marathi",
            "Norwegian",
            "Polish",
            "Punjabi",
            "Romanian",
            "Russian",
            "Sanskrit",
            "Serbian",
            "Spanish",
            "Swedish",
            "Tamil",
            "Telugu",
            "Urdu"
        ],
        "answer_space_ids": [
            "Q35497",
            "Q13955",
            "Q9610",
            "Q9056",
            "Q7411",
            "Q9288",
            "Q1568",
            "Q652",
            "Q5287",
            "Q33673",
            "Q9176",
            "Q36236",
            "Q1571",
            "Q9043",
            "Q809",
            "Q58635",
            "Q7913",
            "Q7737",
            "Q11059",
            "Q9299",
            "Q1321",
            "Q9027",
            "Q5885",
            "Q8097",
            "Q1617"
        ]
    },
    "P1441": {
        "templates": [
            "[X] appears in [Y].",
            "[X] is featured in [Y].",
            "[X] is present in [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 576,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:13:55",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Battlestar Galactica",
            "Coronation Street",
            "Days of Our Lives",
            "Doctor Who",
            "EastEnders",
            "Emmerdale",
            "Family Guy",
            "Harry Potter",
            "Hollyoaks",
            "Home and Away",
            "Iliad",
            "Looney Tunes",
            "Lost",
            "Mahabharata",
            "Neighbours",
            "Pok\u00e9mon core series",
            "Ramayana",
            "Street Fighter",
            "The Bold and the Beautiful",
            "The Divine Comedy",
            "The Lord of the Rings",
            "The Simpsons",
            "The Walking Dead",
            "The Wire",
            "The Young and the Restless"
        ],
        "answer_space_ids": [
            "Q237072",
            "Q945030",
            "Q185059",
            "Q34316",
            "Q607514",
            "Q1247575",
            "Q5930",
            "Q8337",
            "Q1585857",
            "Q1324189",
            "Q8275",
            "Q622435",
            "Q23567",
            "Q8276",
            "Q908708",
            "Q24558579",
            "Q37293",
            "Q288035",
            "Q82729",
            "Q40185",
            "Q15228",
            "Q886",
            "Q232737",
            "Q478360",
            "Q849627"
        ]
    },
    "P1532": {
        "templates": [
            "[X] represents [Y].",
            "[X] has represented [Y] in games.",
            "[X] is a sportsperson for [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:14:58",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Argentina",
            "Belgium",
            "Brazil",
            "Canada",
            "Colombia",
            "Croatia",
            "the Czech Republic",
            "Denmark",
            "France",
            "India",
            "Mexico",
            "Nigeria",
            "Norway",
            "Pakistan",
            "Poland",
            "Portugal",
            "Russia",
            "Serbia",
            "South Korea",
            "Spain",
            "Sweden",
            "Switzerland",
            "Turkey",
            "the United Kingdom",
            "the United States of America"
        ],
        "answer_space_ids": [
            "Q414",
            "Q31",
            "Q155",
            "Q16",
            "Q739",
            "Q224",
            "Q213",
            "Q35",
            "Q142",
            "Q668",
            "Q96",
            "Q1033",
            "Q20",
            "Q843",
            "Q36",
            "Q45",
            "Q159",
            "Q403",
            "Q884",
            "Q29",
            "Q34",
            "Q39",
            "Q43",
            "Q145",
            "Q30"
        ]
    },
    "P2632": {
        "templates": [
            "[X] was detained at [Y].",
            "[X] was held in [Y].",
            "[X] was imprisoned at [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 598,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:15:20",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Alcatraz Island",
            "Auschwitz",
            "Bereza Kartuska prison",
            "Bergen-Belsen concentration camp",
            "Fleet Prison",
            "Gross-Rosen concentration camp",
            "Guantanamo Bay detention camp",
            "Lefortovo Prison",
            "Lukyanivska Prison",
            "Oflag IV-C",
            "Robben Island",
            "Sighet prison",
            "Sobib\u00f3r extermination camp",
            "Theresienstadt Ghetto",
            "Theresienstadt Small Fortress",
            "Tower of London",
            "United States Penitentiary, Florence ADMAX",
            "Vladimir Central Prison",
            "Warsaw Ghetto",
            "Westerbork transit camp",
            "\u0141\u00f3d\u017a Ghetto"
        ],
        "answer_space_ids": [
            "Q131354",
            "Q7341",
            "Q819159",
            "Q7332",
            "Q1427716",
            "Q160268",
            "Q357",
            "Q1346321",
            "Q1581396",
            "Q443620",
            "Q192493",
            "Q1433242",
            "Q152658",
            "Q15111616",
            "Q318861",
            "Q62378",
            "Q75721",
            "Q240549",
            "Q154607",
            "Q323420",
            "Q327895"
        ]
    },
    "P3373": {
        "templates": [
            "[X] and [Y] are siblings.",
            "[X] is the sibling of [Y].",
            "[X] had a sibling named [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 194,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:16:55",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Ibn Saud",
            "Dalida",
            "Tony Abbott",
            "Avicii",
            "Guru Nanak",
            "Kajol",
            "Woody Allen",
            "Trajan",
            "Paolo Veronese",
            "Adam Riess",
            "S\u00f3crates",
            "Hadrian",
            "Paul III",
            "Kylian Mbapp\u00e9",
            "Gary Oldman",
            "Murad II",
            "Henry I the Fowler",
            "Quetzalcoatl",
            "Simeon II of Bulgaria",
            "Matthias Corvinus",
            "Asif Ali Zardari",
            "Gordian II",
            "Katy Perry",
            "Geiseric",
            "Ruud Gullit",
            "Erich Maria Remarque",
            "Joan Crawford",
            "Eug\u00e8ne Delacroix",
            "Teodoro Obiang",
            "Philip the Arab",
            "Vlad III",
            "Victor Emmanuel II of Savoy",
            "Ardashir I",
            "Liza Minnelli",
            "Akhenaten",
            "Malcolm X",
            "Nacho",
            "Paul Samuelson",
            "Barack Obama",
            "Ishtar",
            "Hayreddin Barbarossa",
            "Sergey Shoygu",
            "Patrick Blackett, Baron Blackett",
            "Billie Eilish",
            "Ares",
            "Thal\u00eda",
            "Mswati III",
            "Michael I of Romania",
            "Pyrrhus",
            "Shivaji Bhonsle I",
            "Zico",
            "Ram Narayan",
            "Gustav Holst",
            "Stan Lee",
            "Steve Jobs",
            "Helena Blavatsky",
            "Seleucus I Nicator",
            "Selena",
            "Osman III",
            "Madonna"
        ],
        "answer_space_ids": [
            "Q151509",
            "Q539171",
            "Q348577",
            "Q505476",
            "Q83322",
            "Q147395",
            "Q25089",
            "Q1425",
            "Q9440",
            "Q106454",
            "Q102331",
            "Q1427",
            "Q133001",
            "Q21621995",
            "Q83492",
            "Q131394",
            "Q150620",
            "Q179818",
            "Q1060355",
            "Q188634",
            "Q57373",
            "Q1803",
            "Q42493",
            "Q152127",
            "Q173972",
            "Q47293",
            "Q40475",
            "Q33477",
            "Q57385",
            "Q1817",
            "Q43715",
            "Q168691",
            "Q371319",
            "Q14441",
            "Q81794",
            "Q43303",
            "Q503137",
            "Q102454",
            "Q76",
            "Q47553",
            "Q200582",
            "Q32024",
            "Q184499",
            "Q29564107",
            "Q40901",
            "Q171235",
            "Q57340",
            "Q930013",
            "Q172353",
            "Q239505",
            "Q47526",
            "Q41074",
            "Q200867",
            "Q181900",
            "Q19837",
            "Q189454",
            "Q184176",
            "Q23543",
            "Q199825",
            "Q1744"
        ]
    },
    "P4552": {
        "templates": [
            "[X] is part of the [Y].",
            "[X] is located in the [Y].",
            "[X] belongs to the [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 584,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:18:04",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Adirondack Mountains",
            "Apennine Mountains",
            "Appalachian Mountains",
            "Bernese Alps",
            "Carpathian Mountains",
            "Cascade Range",
            "Catskill Mountains",
            "Dinaric Alps",
            "Dolomites",
            "Drakensberg",
            "Grampian Mountains",
            "Great Dividing Range",
            "Greater Caucasus",
            "Julian Alps",
            "Massif Central",
            "Pennine Alps",
            "Rocky Mountains",
            "Saint Elias Mountains",
            "Scandinavian Mountains",
            "Sierra Nevada",
            "Snowdonia",
            "Tian Shan",
            "Western Ghats",
            "Zagros Mountains"
        ],
        "answer_space_ids": [
            "Q357546",
            "Q1285",
            "Q93332",
            "Q327221",
            "Q1288",
            "Q4558",
            "Q630566",
            "Q189915",
            "Q1283",
            "Q183295",
            "Q1124736",
            "Q192583",
            "Q486986",
            "Q119206",
            "Q190695",
            "Q1270",
            "Q5463",
            "Q48719",
            "Q186547",
            "Q26777",
            "Q867913",
            "Q5474",
            "Q4527",
            "Q167021"
        ]
    },
    "P6886": {
        "templates": [
            "[X]'s works were primarily written in [Y].",
            "[X] composed in [Y].",
            "[X] has used [Y] for writing."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 630,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:19:06",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Ancient Greek",
            "Bengali",
            "Finnish",
            "German",
            "Gujarati",
            "Hindi",
            "Hungarian",
            "Italian",
            "Japanese",
            "Kannada",
            "Latin",
            "Malayalam",
            "Marathi",
            "Odia",
            "Persian",
            "Polish",
            "Portuguese",
            "Punjabi",
            "Russian",
            "Sanskrit",
            "Swedish",
            "Tagalog",
            "Tamil",
            "Telugu",
            "Urdu"
        ],
        "answer_space_ids": [
            "Q35497",
            "Q9610",
            "Q1412",
            "Q188",
            "Q5137",
            "Q1568",
            "Q9067",
            "Q652",
            "Q5287",
            "Q33673",
            "Q397",
            "Q36236",
            "Q1571",
            "Q33810",
            "Q9168",
            "Q809",
            "Q5146",
            "Q58635",
            "Q7737",
            "Q11059",
            "Q9027",
            "Q34057",
            "Q5885",
            "Q8097",
            "Q1617"
        ]
    },
    "P7937": {
        "templates": [
            "[X] is a form of [Y].",
            "[X] is [Y].",
            "[X] is structured as a/an [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 612,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:19:44",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "aria",
            "church cantata",
            "compilation album",
            "extended play",
            "instrumental music",
            "live album",
            "march",
            "mass",
            "maxi single",
            "mixtape",
            "motet",
            "musical",
            "novella",
            "opera",
            "oratorio",
            "piano piece",
            "promotional recording",
            "remix album",
            "song cycle",
            "soundtrack album",
            "studio album",
            "suite",
            "symphonic poem",
            "symphony",
            "waltz"
        ],
        "answer_space_ids": [
            "Q178122",
            "Q11499279",
            "Q222910",
            "Q169930",
            "Q639197",
            "Q209939",
            "Q211025",
            "Q217295",
            "Q3046922",
            "Q1892995",
            "Q188285",
            "Q2743",
            "Q149537",
            "Q1344",
            "Q85477",
            "Q1746015",
            "Q728121",
            "Q963099",
            "Q893466",
            "Q4176708",
            "Q208569",
            "Q203005",
            "Q271802",
            "Q9734",
            "Q8701407"
        ]
    },
    "P7959": {
        "templates": [
            "[X] is located in the historic county of [Y].",
            "[X] is where [Y] was.",
            "[X] is situated in the historic county known as [Y]."
        ],
        "template_index": 0,
        "model_name_or_path": "gpt2",
        "num_original_instances": 600,
        "subsampled": null,
        "reduction": "sum",
        "timestamp": "2023-12-12 14:20:56",
        "dataset_path": "/vol/home-vol2/ml/wilandjl/workspace/transformer-knowledge-probe/data/BEAR",
        "dataset_name": "BEAR",
        "relation_info": {},
        "metric_values": {},
        "answer_space_labels": [
            "Aberdeenshire",
            "Argyll",
            "Caernarfonshire",
            "Cornwall",
            "County Antrim",
            "County Clare",
            "County Cork",
            "County Donegal",
            "County Down",
            "County Dublin",
            "County Kerry",
            "County Mayo",
            "County Wicklow",
            "Cumberland",
            "Dumfriesshire",
            "Glamorgan",
            "Inverness-shire",
            "Lanarkshire",
            "Middlesex",
            "Monmouthshire",
            "Ross-shire",
            "Stirlingshire",
            "Sussex",
            "Westmorland",
            "Yorkshire"
        ],
        "answer_space_ids": [
            "Q3290674",
            "Q652539",
            "Q731669",
            "Q23148",
            "Q189592",
            "Q181862",
            "Q162475",
            "Q179424",
            "Q190684",
            "Q173500",
            "Q184469",
            "Q178626",
            "Q182591",
            "Q23360",
            "Q1247384",
            "Q870815",
            "Q1247390",
            "Q530296",
            "Q19186",
            "Q1245075",
            "Q978599",
            "Q1229763",
            "Q23346",
            "Q23326",
            "Q163"
        ]
    }
}